{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd37bb9b-b5a8-4754-881d-8ddac37d8872",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# GFL Prototype for P&ID Symbol Detection\n",
    "# Implementation of Kim et al.'s two-network strategy with GFL\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bbd62bc-c067-4469-ab49-2c3cb80f8e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c802fbe5-7678-4596-ba7a-f20a42091453",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 1. GFL Loss Functions Implementation\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60674690-4ec5-45a1-be8e-2ac9ad658328",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QualityFocalLoss(nn.Module):\n",
    "    \"\"\"Quality Focal Loss implementation for GFL detector[4][9].\"\"\"\n",
    "    \n",
    "    def __init__(self, beta=2.0, reduction='mean'):\n",
    "        super(QualityFocalLoss, self).__init__()\n",
    "        self.beta = beta\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            inputs: Predicted logits [N, num_classes]\n",
    "            targets: Target IoU-aware classification scores [N, num_classes]\n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(inputs)\n",
    "        ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        modulating_factor = torch.pow(torch.abs(targets - probs), self.beta)\n",
    "        loss = modulating_factor * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        return loss\n",
    "\n",
    "class DistributionFocalLoss(nn.Module):\n",
    "    \"\"\"Distribution Focal Loss for bounding box regression[4][9].\"\"\"\n",
    "    \n",
    "    def __init__(self, reduction='mean'):\n",
    "        super(DistributionFocalLoss, self).__init__()\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pred: Predicted distribution [N, n+1] before softmax\n",
    "            target: Target distance values [N]\n",
    "        \"\"\"\n",
    "        dis_left = target.long()\n",
    "        dis_right = dis_left + 1\n",
    "        weight_left = dis_right.float() - target\n",
    "        weight_right = target - dis_left.float()\n",
    "        \n",
    "        loss = F.cross_entropy(pred, dis_left, reduction='none') * weight_left + \\\n",
    "               F.cross_entropy(pred, dis_right, reduction='none') * weight_right\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0d80a8-2662-4d93-98df-6504d916e4f4",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 2. ResNet Backbone Implementation\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "095dfbf3-5fb9-4aae-8f6a-e958eb24964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"Basic ResNet block for feature extraction[17][18].\"\"\"\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, \n",
    "                              padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, \n",
    "                              padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, \n",
    "                         stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNetBackbone(nn.Module):\n",
    "    \"\"\"ResNet backbone for GFL detector[17][20].\"\"\"\n",
    "    \n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNetBackbone, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Feature pyramid levels\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        \n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract multi-scale features\n",
    "        c1 = F.relu(self.bn1(self.conv1(x)))\n",
    "        c1 = self.maxpool(c1)\n",
    "        \n",
    "        c2 = self.layer1(c1)  # 1/4 resolution\n",
    "        c3 = self.layer2(c2)  # 1/8 resolution\n",
    "        c4 = self.layer3(c3)  # 1/16 resolution\n",
    "        c5 = self.layer4(c4)  # 1/32 resolution\n",
    "        \n",
    "        return [c2, c3, c4, c5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab80be8-79a9-4dc3-8985-4084c56c41bf",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 3. GFL Detection Head Implementation\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "669fbb78-ad95-4d7b-ac0a-87fef275ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GFLHead(nn.Module):\n",
    "    \"\"\"GFL detection head with quality-aware classification and distribution regression[4][9].\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels=256, num_classes=8, num_convs=4, reg_max=16):\n",
    "        super(GFLHead, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.reg_max = reg_max\n",
    "        \n",
    "        # Shared convolutions\n",
    "        self.cls_convs = nn.ModuleList()\n",
    "        self.reg_convs = nn.ModuleList()\n",
    "        \n",
    "        for i in range(num_convs):\n",
    "            chn = in_channels if i == 0 else in_channels\n",
    "            self.cls_convs.append(\n",
    "                nn.Conv2d(chn, in_channels, 3, stride=1, padding=1))\n",
    "            self.reg_convs.append(\n",
    "                nn.Conv2d(chn, in_channels, 3, stride=1, padding=1))\n",
    "        \n",
    "        # Output layers\n",
    "        self.gfl_cls = nn.Conv2d(in_channels, num_classes, 3, padding=1)\n",
    "        self.gfl_reg = nn.Conv2d(in_channels, 4 * (reg_max + 1), 3, padding=1)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize layer weights[4].\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, std=0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, feats):\n",
    "        \"\"\"Forward pass through GFL head.\"\"\"\n",
    "        cls_outputs = []\n",
    "        reg_outputs = []\n",
    "        \n",
    "        for feat in feats:\n",
    "            cls_feat = feat\n",
    "            reg_feat = feat\n",
    "            \n",
    "            # Classification branch\n",
    "            for cls_conv in self.cls_convs:\n",
    "                cls_feat = F.relu(cls_conv(cls_feat))\n",
    "            cls_score = self.gfl_cls(cls_feat)\n",
    "            \n",
    "            # Regression branch\n",
    "            for reg_conv in self.reg_convs:\n",
    "                reg_feat = F.relu(reg_conv(reg_feat))\n",
    "            bbox_pred = self.gfl_reg(reg_feat)\n",
    "            \n",
    "            cls_outputs.append(cls_score)\n",
    "            reg_outputs.append(bbox_pred)\n",
    "        \n",
    "        return cls_outputs, reg_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89fcce0-6c78-41c2-8cec-0a70d10df051",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 4. Complete GFL Detector\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f403281-1c29-45e0-a623-6176670239ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GFLDetector(nn.Module):\n",
    "    \"\"\"Complete GFL detector combining ResNet backbone and GFL head[4][11].\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=8, reg_max=16):\n",
    "        super(GFLDetector, self).__init__()\n",
    "        \n",
    "        # ResNet-50 backbone\n",
    "        self.backbone = ResNetBackbone(BasicBlock, [3, 4, 6, 3], num_classes)\n",
    "        \n",
    "        # Feature Pyramid Network (simplified)\n",
    "        self.fpn = nn.ModuleList([\n",
    "            nn.Conv2d(64, 256, 1),  # P2\n",
    "            nn.Conv2d(128, 256, 1),  # P3\n",
    "            nn.Conv2d(256, 256, 1),  # P4\n",
    "            nn.Conv2d(512, 256, 1),  # P5\n",
    "        ])\n",
    "        \n",
    "        # GFL detection head\n",
    "        self.head = GFLHead(256, num_classes, reg_max=reg_max)\n",
    "        \n",
    "        # Loss functions\n",
    "        self.qfl_loss = QualityFocalLoss()\n",
    "        self.dfl_loss = DistributionFocalLoss()\n",
    "    \n",
    "    def forward(self, x, targets=None):\n",
    "        # Backbone feature extraction\n",
    "        backbone_feats = self.backbone(x)\n",
    "        \n",
    "        # FPN processing\n",
    "        fpn_feats = []\n",
    "        for i, feat in enumerate(backbone_feats):\n",
    "            fpn_feats.append(self.fpn[i](feat))\n",
    "        \n",
    "        # Detection head\n",
    "        cls_outputs, reg_outputs = self.head(fpn_feats)\n",
    "        \n",
    "        if self.training and targets is not None:\n",
    "            # Calculate losses during training\n",
    "            return self.calculate_losses(cls_outputs, reg_outputs, targets)\n",
    "        else:\n",
    "            # Return predictions during inference\n",
    "            return cls_outputs, reg_outputs\n",
    "    \n",
    "    def calculate_losses(self, cls_outputs, reg_outputs, targets):\n",
    "        \"\"\"Calculate GFL losses[4].\"\"\"\n",
    "        # This is a simplified loss calculation\n",
    "        # In practice, you'd need proper anchor generation and matching\n",
    "        total_loss = 0\n",
    "        \n",
    "        for cls_out, reg_out in zip(cls_outputs, reg_outputs):\n",
    "            # Dummy loss calculation - replace with proper implementation\n",
    "            cls_loss = self.qfl_loss(cls_out.flatten(2).permute(0, 2, 1).flatten(0, 1), \n",
    "                                   torch.zeros_like(cls_out.flatten(2).permute(0, 2, 1).flatten(0, 1)))\n",
    "            total_loss += cls_loss\n",
    "        \n",
    "        return {'total_loss': total_loss, 'cls_loss': cls_loss}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dd86de-52d4-4df6-b835-5bbd9a3d432f",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 5. Data Preprocessing for Two-Network Strategy\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f03f84b3-353d-4a10-9a41-7f3ee662fb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIDSymbolDataset(Dataset):\n",
    "    \"\"\"Dataset class for P&ID symbols implementing Kim et al.'s strategy[11].\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir, mode='small', transform=None, symbol_size_threshold=700):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.mode = mode  # 'small' or 'large'\n",
    "        self.transform = transform\n",
    "        self.threshold = symbol_size_threshold\n",
    "        self.samples = self._load_samples()\n",
    "    \n",
    "    def _load_samples(self):\n",
    "        \"\"\"Load and filter samples based on symbol size[11].\"\"\"\n",
    "        samples = []\n",
    "        \n",
    "        # Load Paliwal dataset\n",
    "        paliwal_dir = self.data_dir / 'raw' / 'paliwal_dataset'\n",
    "        \n",
    "        for folder in paliwal_dir.iterdir():\n",
    "            if folder.is_dir():\n",
    "                try:\n",
    "                    # Load symbol annotations\n",
    "                    symbols_file = folder / 'symbols.npy'\n",
    "                    if symbols_file.exists():\n",
    "                        symbols_data = np.load(symbols_file, allow_pickle=True).item()\n",
    "                        \n",
    "                        # Filter by symbol size\n",
    "                        filtered_symbols = self._filter_by_size(symbols_data)\n",
    "                        if filtered_symbols:\n",
    "                            samples.append({\n",
    "                                'folder': folder,\n",
    "                                'symbols': filtered_symbols\n",
    "                            })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {folder}: {e}\")\n",
    "        \n",
    "        print(f\"Loaded {len(samples)} samples for {self.mode} network\")\n",
    "        return samples\n",
    "    \n",
    "    def _filter_by_size(self, symbols_data):\n",
    "        \"\"\"Filter symbols based on diagonal length[11].\"\"\"\n",
    "        filtered = []\n",
    "        \n",
    "        if 'bounding_box' in symbols_data:\n",
    "            for i, bbox in enumerate(symbols_data['bounding_box']):\n",
    "                if len(bbox) >= 4:\n",
    "                    x1, y1, x2, y2 = bbox[:4]\n",
    "                    diagonal = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "                    \n",
    "                    if self.mode == 'small' and diagonal <= self.threshold:\n",
    "                        filtered.append(i)\n",
    "                    elif self.mode == 'large' and diagonal > self.threshold:\n",
    "                        filtered.append(i)\n",
    "        \n",
    "        return filtered\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Load image (this is simplified - you'd need actual image loading)\n",
    "        # For now, return dummy data\n",
    "        if self.mode == 'small':\n",
    "            # Return patch-based data for small symbols\n",
    "            image = torch.randn(3, 512, 512)  # Dummy patch\n",
    "        else:\n",
    "            # Return scaled-down full image for large symbols\n",
    "            image = torch.randn(3, 1024, 1024)  # Dummy full image\n",
    "        \n",
    "        # Create dummy target\n",
    "        target = {\n",
    "            'boxes': torch.tensor([[100, 100, 200, 200]], dtype=torch.float32),\n",
    "            'labels': torch.tensor([1], dtype=torch.long),\n",
    "            'scores': torch.tensor([1.0], dtype=torch.float32)\n",
    "        }\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd97c0-423a-4239-a235-8f5857c40552",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 6. Adaptive NMS Implementation\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f23ead9-b0fe-4b00-b59e-35199f441261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_nms(boxes, scores, labels, iou_thresholds, score_threshold=0.05):\n",
    "    \"\"\"\n",
    "    Adaptive Non-Maximum Suppression with class-specific IoU thresholds[24][25].\n",
    "    \n",
    "    Args:\n",
    "        boxes: Tensor [N, 4] in (x1, y1, x2, y2) format\n",
    "        scores: Tensor [N] detection scores\n",
    "        labels: Tensor [N] class labels\n",
    "        iou_thresholds: Dict mapping class_id to IoU threshold\n",
    "        score_threshold: Minimum score threshold\n",
    "    \"\"\"\n",
    "    # Filter by score threshold\n",
    "    valid_mask = scores > score_threshold\n",
    "    boxes = boxes[valid_mask]\n",
    "    scores = scores[valid_mask]\n",
    "    labels = labels[valid_mask]\n",
    "    \n",
    "    if len(boxes) == 0:\n",
    "        return torch.empty(0, dtype=torch.long)\n",
    "    \n",
    "    # Sort by scores in descending order\n",
    "    sorted_indices = torch.argsort(scores, descending=True)\n",
    "    boxes = boxes[sorted_indices]\n",
    "    scores = scores[sorted_indices]\n",
    "    labels = labels[sorted_indices]\n",
    "    \n",
    "    keep = []\n",
    "    suppressed = torch.zeros(len(boxes), dtype=torch.bool)\n",
    "    \n",
    "    for i in range(len(boxes)):\n",
    "        if suppressed[i]:\n",
    "            continue\n",
    "            \n",
    "        keep.append(sorted_indices[i])\n",
    "        current_box = boxes[i:i+1]\n",
    "        current_label = labels[i]\n",
    "        \n",
    "        # Get class-specific IoU threshold\n",
    "        iou_threshold = iou_thresholds.get(current_label.item(), 0.5)\n",
    "        \n",
    "        # Calculate IoU with remaining boxes of the same class\n",
    "        remaining_boxes = boxes[i+1:]\n",
    "        remaining_labels = labels[i+1:]\n",
    "        same_class_mask = remaining_labels == current_label\n",
    "        \n",
    "        if same_class_mask.any():\n",
    "            same_class_boxes = remaining_boxes[same_class_mask]\n",
    "            ious = calculate_iou(current_box, same_class_boxes)\n",
    "            \n",
    "            # Suppress boxes with high IoU\n",
    "            suppress_mask = ious > iou_threshold\n",
    "            \n",
    "            # Map back to global indices\n",
    "            global_suppress_indices = torch.where(same_class_mask)[0] + i + 1\n",
    "            suppressed[global_suppress_indices[suppress_mask]] = True\n",
    "    \n",
    "    return torch.tensor(keep, dtype=torch.long)\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calculate IoU between box1 and box2[29].\"\"\"\n",
    "    # box1: [1, 4], box2: [N, 4]\n",
    "    \n",
    "    # Calculate intersection\n",
    "    x1_max = torch.max(box1[:, 0], box2[:, 0])\n",
    "    y1_max = torch.max(box1[:, 1], box2[:, 1])\n",
    "    x2_min = torch.min(box1[:, 2], box2[:, 2])\n",
    "    y2_min = torch.min(box1[:, 3], box2[:, 3])\n",
    "    \n",
    "    intersection = torch.clamp(x2_min - x1_max, min=0) * torch.clamp(y2_min - y1_max, min=0)\n",
    "    \n",
    "    # Calculate areas\n",
    "    area1 = (box1[:, 2] - box1[:, 0]) * (box1[:, 3] - box1[:, 1])\n",
    "    area2 = (box2[:, 2] - box2[:, 0]) * (box2[:, 3] - box2[:, 1])\n",
    "    \n",
    "    # Calculate union\n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    return intersection / (union + 1e-6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea4001f-3170-4617-b8d5-dc1407ee059c",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 7. Training Setup and Utilities\n",
    "# =============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64d7c306-3212-41bc-84cf-35af0bd2d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gfl_models(num_classes=8):\n",
    "    \"\"\"Create both small and large symbol detection networks[11].\"\"\"\n",
    "    \n",
    "    # Small symbol network (for patches)\n",
    "    small_net = GFLDetector(num_classes=num_classes, reg_max=16)\n",
    "    \n",
    "    # Large symbol network (for full images)\n",
    "    large_net = GFLDetector(num_classes=num_classes, reg_max=16)\n",
    "    \n",
    "    return small_net, large_net\n",
    "\n",
    "def setup_training(model, learning_rate=1e-4):\n",
    "    \"\"\"Setup optimizer and scheduler for training[4].\"\"\"\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[8, 11], gamma=0.1)\n",
    "    \n",
    "    return optimizer, scheduler\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, device):\n",
    "    \"\"\"Train for one epoch[4].\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (images, targets) in enumerate(dataloader):\n",
    "        images = images.to(device)\n",
    "        # Note: targets processing would be more complex in practice\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images, targets)\n",
    "        loss = outputs['total_loss']\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Batch {batch_idx}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b19e3f0-333c-42c8-b849-d1ce16b6d447",
   "metadata": {},
   "source": [
    "# =============================================================================\n",
    "# 8. Prototype Testing and Visualization\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e591fc3-85d6-4c6a-8297-407a73af96e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing GFL Prototype Implementation...\n",
      "Small network parameters: 26,427,276\n",
      "Large network parameters: 26,427,276\n",
      "Number of feature levels: 4\n",
      "Level 0: cls_shape=torch.Size([2, 8, 128, 128]), reg_shape=torch.Size([2, 68, 128, 128])\n",
      "Level 1: cls_shape=torch.Size([2, 8, 64, 64]), reg_shape=torch.Size([2, 68, 64, 64])\n",
      "Level 2: cls_shape=torch.Size([2, 8, 32, 32]), reg_shape=torch.Size([2, 68, 32, 32])\n",
      "Level 3: cls_shape=torch.Size([2, 8, 16, 16]), reg_shape=torch.Size([2, 68, 16, 16])\n",
      "QFL Loss: 0.1454\n",
      "DFL Loss: 3.3212\n",
      "NMS kept 2 detections: tensor([0, 2])\n",
      "✅ GFL Prototype test completed successfully!\n",
      "\n",
      "============================================================\n",
      "GFL DETECTOR ARCHITECTURE\n",
      "============================================================\n",
      "\n",
      "    Input Image\n",
      "         ↓\n",
      "    ResNet Backbone (Feature Extraction)\n",
      "         ↓\n",
      "    Feature Pyramid Network\n",
      "         ↓\n",
      "    GFL Detection Head\n",
      "    ├── Classification Branch (QFL)\n",
      "    └── Regression Branch (DFL)\n",
      "         ↓\n",
      "    Post-processing (Adaptive NMS)\n",
      "         ↓\n",
      "    Final Detections\n",
      "    \n",
      "\n",
      "Two-Network Strategy:\n",
      "├── Small Symbol Network: Patch-based detection (symbols < 700px)\n",
      "└── Large Symbol Network: Full-image detection (symbols > 700px)\n",
      "\n",
      "============================================================\n",
      "NEXT STEPS\n",
      "============================================================\n",
      "1. Implement proper data loading from Paliwal dataset\n",
      "2. Add anchor generation and matching logic\n",
      "3. Implement proper loss calculation with ground truth\n",
      "4. Add evaluation metrics (mAP, precision, recall)\n",
      "5. Create training loop with validation\n",
      "6. Implement inference pipeline with visualization\n"
     ]
    }
   ],
   "source": [
    "def test_gfl_prototype():\n",
    "    \"\"\"Test the GFL implementation with dummy data[4].\"\"\"\n",
    "    \n",
    "    print(\"Testing GFL Prototype Implementation...\")\n",
    "    \n",
    "    # Create models\n",
    "    small_net, large_net = create_gfl_models(num_classes=8)\n",
    "    \n",
    "    print(f\"Small network parameters: {sum(p.numel() for p in small_net.parameters()):,}\")\n",
    "    print(f\"Large network parameters: {sum(p.numel() for p in large_net.parameters()):,}\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    dummy_input = torch.randn(2, 3, 512, 512)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        small_net.eval()\n",
    "        cls_outputs, reg_outputs = small_net(dummy_input)\n",
    "        \n",
    "        print(f\"Number of feature levels: {len(cls_outputs)}\")\n",
    "        for i, (cls_out, reg_out) in enumerate(zip(cls_outputs, reg_outputs)):\n",
    "            print(f\"Level {i}: cls_shape={cls_out.shape}, reg_shape={reg_out.shape}\")\n",
    "    \n",
    "    # Test loss functions\n",
    "    qfl = QualityFocalLoss()\n",
    "    dfl = DistributionFocalLoss()\n",
    "    \n",
    "    dummy_cls_pred = torch.randn(100, 8)\n",
    "    dummy_cls_target = torch.rand(100, 8)\n",
    "    dummy_reg_pred = torch.randn(100, 17)  # reg_max + 1\n",
    "    dummy_reg_target = torch.rand(100) * 16\n",
    "    \n",
    "    qfl_loss = qfl(dummy_cls_pred, dummy_cls_target)\n",
    "    dfl_loss = dfl(dummy_reg_pred, dummy_reg_target)\n",
    "    \n",
    "    print(f\"QFL Loss: {qfl_loss.item():.4f}\")\n",
    "    print(f\"DFL Loss: {dfl_loss.item():.4f}\")\n",
    "    \n",
    "    # Test adaptive NMS\n",
    "    dummy_boxes = torch.tensor([\n",
    "        [10, 10, 50, 50],\n",
    "        [15, 15, 55, 55],\n",
    "        [100, 100, 150, 150],\n",
    "        [105, 105, 155, 155]\n",
    "    ], dtype=torch.float32)\n",
    "    \n",
    "    dummy_scores = torch.tensor([0.9, 0.8, 0.85, 0.75])\n",
    "    dummy_labels = torch.tensor([0, 0, 1, 1])\n",
    "    \n",
    "    iou_thresholds = {0: 0.5, 1: 0.6}  # Class-specific thresholds\n",
    "    \n",
    "    keep_indices = adaptive_nms(dummy_boxes, dummy_scores, dummy_labels, iou_thresholds)\n",
    "    print(f\"NMS kept {len(keep_indices)} detections: {keep_indices}\")\n",
    "    \n",
    "    print(\"✅ GFL Prototype test completed successfully!\")\n",
    "\n",
    "def visualize_architecture():\n",
    "    \"\"\"Visualize the GFL architecture[4].\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GFL DETECTOR ARCHITECTURE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\"\"\n",
    "    Input Image\n",
    "         ↓\n",
    "    ResNet Backbone (Feature Extraction)\n",
    "         ↓\n",
    "    Feature Pyramid Network\n",
    "         ↓\n",
    "    GFL Detection Head\n",
    "    ├── Classification Branch (QFL)\n",
    "    └── Regression Branch (DFL)\n",
    "         ↓\n",
    "    Post-processing (Adaptive NMS)\n",
    "         ↓\n",
    "    Final Detections\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"\\nTwo-Network Strategy:\")\n",
    "    print(\"├── Small Symbol Network: Patch-based detection (symbols < 700px)\")\n",
    "    print(\"└── Large Symbol Network: Full-image detection (symbols > 700px)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run prototype tests\n",
    "    test_gfl_prototype()\n",
    "    visualize_architecture()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"NEXT STEPS\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"1. Implement proper data loading from Paliwal dataset\")\n",
    "    print(\"2. Add anchor generation and matching logic\")\n",
    "    print(\"3. Implement proper loss calculation with ground truth\")\n",
    "    print(\"4. Add evaluation metrics (mAP, precision, recall)\")\n",
    "    print(\"5. Create training loop with validation\")\n",
    "    print(\"6. Implement inference pipeline with visualization\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
